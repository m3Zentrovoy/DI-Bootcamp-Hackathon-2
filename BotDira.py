# import joblib
# from dotenv import load_dotenv
# import os
# from telegram import Update
# from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
#
# import torch
# from transformers import pipeline
#
# # Load environment variables from .env file
# load_dotenv()
# TOKEN = os.getenv("API_TOKEN")
#
# async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     user_text = update.message.text     # Take text from user
#     chat_id = update.message.chat_id    # Take chat_id with the user
#     print(f"Message from {chat_id}: {user_text}")
#
#     # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
#     model = joblib.load('review_model.pkl')
#
#     # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
#     text = user_text
#     prediction = model.predict([text])[0]
#
#     if prediction == 1:
#         await update.message.reply_text(f"You said: ‚úÖ Positive review")
#     else:
#         await update.message.reply_text(f"You said: ‚ùå Negative review")
#
#     # PART WITH BIG MODEL
#     # # Create the pipeline
#     # sentiment_pipe = pipeline("sentiment-analysis")
#     #
#     # # Use the pipeline
#     # result = sentiment_pipe(user_text)
#     #
#     # # Example: reply back
#     # await update.message.reply_text(f"You said: {result[0]['label']}")
#
# async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     await update.message.reply_text("Hi! Send me a message üòé")
#
# # Main bot setup
# if __name__ == "__main__":
#     app = ApplicationBuilder().token(TOKEN).build()
#
#     app.add_handler(CommandHandler("start", start))
#     app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
#
#     print("Bot is running...")
#     app.run_polling()
#

######################################################################
######################################################################
######################################################################

import torch
from transformers import pipeline

import os
from dotenv import load_dotenv
import joblib
import pandas as pd
from telegram import Update
from telegram.ext import (
    ApplicationBuilder, MessageHandler, ContextTypes, filters
)
import datetime

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
load_dotenv()
TOKEN = os.getenv("API_TOKEN")
ID_ILIA = os.getenv("ID_ILIA")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = joblib.load("review_model_1.pkl") # Our model
sentiment_pipe = pipeline("sentiment-analysis") # Our spare model



# ID —á–∞—Ç–∞ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞ (–º–æ–∂–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–π ID)
MODERATOR_CHAT_ID = ID_ILIA  # ‚Üê –∑–∞–º–µ–Ω–∏ –Ω–∞ —Å–≤–æ–π Telegram ID

# –ü—É—Ç—å –∫ CSV –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
LOG_FILE = "flagged_comments.csv"

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ CSV –µ—Å–ª–∏ –æ–Ω –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
try:
    pd.read_csv(LOG_FILE)
except FileNotFoundError:
    pd.DataFrame(columns=["datetime", "user", "text", "negative_score"]).to_csv(LOG_FILE, index=False)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –≥—Ä—É–ø–ø–∞—Ö
async def moderate_comment(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    user = update.message.from_user.full_name
    print(text)

    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    probas = model.predict_proba([text])[0] # Our model
    negative_score = probas[0]
    positive_score = probas[1]
    print(probas)

    result = sentiment_pipe(text) # Our spare model
    # print(result[0]['score'])
    print(result[0]['label'])

    # –ü–æ—Ä–æ–≥ –æ—Ç—Å–µ—á–µ–Ω–∏—è
    # if result[0]['label'] == 'NEGATIVE': # Our spare model
    if negative_score > 0.6 and result[0]['label'] == 'NEGATIVE': # Our  model
        # –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        await update.message.delete()

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä—É
        await context.bot.send_message(
            chat_id=MODERATOR_CHAT_ID,
            text=f"üö® *Flagged comment removed!*\n\n"
                 f"*User:* {user}\n"
                 f"*Negative score:* {round(negative_score * 100, 2)}%\n"
                 f"*Text:* `{text}`",
            parse_mode='Markdown'
        )

        # –õ–æ–≥–∏—Ä—É–µ–º
        new_entry = {
            "datetime": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "user": user,
            "text": text,
            "negative_score": round(negative_score * 100, 2)
        }
        log_df = pd.read_csv(LOG_FILE)
        log_df = pd.concat([log_df, pd.DataFrame([new_entry])], ignore_index=True)
        log_df.to_csv(LOG_FILE, index=False)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
application = ApplicationBuilder().token(TOKEN).build()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –≥—Ä—É–ø–ø–∞—Ö
application.add_handler(MessageHandler(filters.TEXT & filters.ChatType.GROUPS, moderate_comment))

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
application.run_polling()










    # # PART WITH BIG MODEL
    # # Create the pipeline
    # sentiment_pipe = pipeline("sentiment-analysis")
    #
    # # Use the pipeline
    # result = sentiment_pipe(user_text)
    #
    # # Example: reply back
    # await update.message.reply_text(f"You said: {result[0]['label']}")